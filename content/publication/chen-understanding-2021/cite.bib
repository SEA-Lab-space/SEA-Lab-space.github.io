@inproceedings{chen_understanding_2021,
 abstract = {As wearable devices move toward the face (i.e. smart earbuds, glasses), there is an increasing need to facilitate intuitive interactions with these devices. Current sensing techniques can already detect many mouth-based gestures; however, usersâ€™ preferences of these gestures are not fully understood. In this paper, we investigate the design space and usability of mouth-based microgestures. We first conducted brainstorming sessions (N=16) and compiled an extensive set of 86 user-defined gestures. Then, with an online survey (N=50), we assessed the physical and mental demand of our gesture set and identified a subset of 14 gestures that can be performed easily and naturally. Finally, we conducted a remote Wizard-of-Oz usability study (N=11) mapping gestures to various daily smartphone operations under a sitting and walking context. From these studies, we develop a taxonomy for mouth gestures, finalize a practical gesture set for common applications, and provide design guidelines for future mouth-based gesture interactions.},
 address = {Virtual Event USA},
 author = {Chen, Victor and Xu, Xuhai and Li, Richard and Shi, Yuanchun and Patel, Shwetak and Wang, Yuntao},
 booktitle = {Proceedings of the Designing Interactive Systems Conference},
 doi = {10.1145/3461778.3462004},
 file = {Chen et al. - 2021 - Understanding the Design Space of Mouth Microgestu.pdf:/Users/orsonxu/Zotero/storage/3E7HILPB/Chen et al. - 2021 - Understanding the Design Space of Mouth Microgestu.pdf:application/pdf},
 isbn = {978-1-4503-8476-6},
 language = {en},
 month = {June},
 pages = {1068--1081},
 publisher = {ACM},
 title = {Understanding the Design Space of Mouth Microgestures},
 url = {https://dl.acm.org/doi/10.1145/3461778.3462004},
 urldate = {2021-10-07},
 year = {2021}
}
