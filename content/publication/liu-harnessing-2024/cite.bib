@misc{liu_harnessing_2024,
 abstract = {Despite the growing interest in leveraging Large Language Models (LLMs) for content analysis, current studies have primarily focused on text-based content. In the present work, we explored the potential of LLMs in assisting video content analysis by conducting a case study that followed a new workflow of LLM-assisted multimodal content analysis. The workflow encompasses codebook design, prompt engineering, LLM processing, and human evaluation. We strategically crafted annotation prompts to get LLM Annotations in structured form and explanation prompts to generate LLM Explanations for a better understanding of LLM reasoning and transparency. To test LLM’s video annotation capabilities, we analyzed 203 keyframes extracted from 25 YouTube short videos about depression. We compared the LLM Annotations with those of two human coders and found that LLM has higher accuracy in object and activity Annotations than emotion and genre Annotations. Moreover, we identified the potential and limitations of LLM’s capabilities in annotating videos. Based on the findings, we explore opportunities and challenges for future research and improvements to the workflow. We also discuss ethical concerns surrounding future studies based on LLM-assisted video analysis.},
 author = {Liu, Jiaying Lizzy and Wang, Yunlong and Lyu, Yao and Su, Yiheng and Niu, Shuo and Xu, Xuhai and Zhang, Yan},
 doi = {10.1145/3678884.3681850},
 file = {PDF:/Users/orsonxu/Zotero/storage/89IV5BB5/Liu et al. - 2024 - Harnessing LLMs for Automated Video Content Analysis An Exploratory Workflow of Short Videos on Dep.pdf:application/pdf},
 language = {en},
 month = {July},
 note = {arXiv:2406.19528 [cs]},
 shorttitle = {Harnessing LLMs for Automated Video Content Analysis},
 title = {Harnessing LLMs for Automated Video Content Analysis: An Exploratory Workflow of Short Videos on Depression},
 url = {http://arxiv.org/abs/2406.19528},
 urldate = {2024-09-28},
 year = {2024}
}
