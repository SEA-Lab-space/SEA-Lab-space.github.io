---
title: 'EarBuddy: Enabling On-Face Interaction via Wireless Earbuds'
authors:
- Xuhai Xu
- Haitian Shi
- Xin Yi
- Wenjia Liu
- Yukang Yan
- Yuanchun Shi
- Alex Mariakakis
- Jennifer Mankoff
- Anind K Dey
date: '2020-01-01'
publishDate: '2024-09-29T06:40:21.760298Z'
publication_types:
- paper-conference
publication: '*Proceedings of the ACM Conference on Human Factors in Computing Systems*'
abstract: Past research regarding on-body interaction typically requires custom sensors,
  limiting their scalability and generalizability. We propose EarBuddy, a real-time
  system that leverages the microphone in commercial wireless earbuds to detect tapping
  and sliding gestures near the face and ears. We develop a design space to generate
  27 valid gestures and conducted a user study (N=16) to select the eight gestures
  that were optimal for both human preference and microphone detectability. We collected
  a dataset on those eight gestures (N=20) and trained deep learning models for gesture
  detection and classiﬁcation. Our optimized classiﬁer achieved an accuracy of 95.3%.
  Finally, we conducted a user study (N=12) to evaluate EarBuddy’s usability. Our
  results show that EarBuddy can facilitate novel interaction and that users feel
  very positively about the system. EarBuddy provides a new eyes-free, socially acceptable
  input method that is compatible with commercial wireless earbuds and has the potential
  for scalability and generalizability.
---
